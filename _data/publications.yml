main:
  - title: "Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in"
    authors: <strong><u>Xiaoqian Shen</u></strong>, Min-Hung Chen, Yu-Chiang Frank Wang, Mohamed Elhoseiny, Ryo Hachiuma
    conference: Arxiv preprint 2025
    image: ./assets/img/pub/zoom.png
    code: https://github.com/xiaoqian-shen/Zoom-Zero
    page: https://xiaoqian-shen.github.io/Zoom-Zero/
    is_preprint: true
    type: mllm
    notes: Work done at Nvidia

  - title: "Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding"
    authors: <strong><u>Xiaoqian Shen</u></strong>, Wenxuan Zhang, Jun Chen, Mohamed Elhoseiny
    conference_short: NeurIPS
    conference: NeurIPS 2025
    image: ./assets/img/pub/vgent.png
    code: https://github.com/xiaoqian-shen/Vgent
    page: https://xiaoqian-shen.github.io/Vgent/
    notes: Spotlight (Top 3%)
    type: mllm

  - title: "LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding"
    authors: <strong><u>Xiaoqian Shen</u></strong>, Yunyang Xiong, Changsheng Zhao, Lemeng Wu, Jun Chen, Chenchen Zhu, Zechun Liu, Fanyi Xiao, Balakrishnan Varadarajan, Florian Bordes, Zhuang Liu, Hu Xu, Hyunwoo J. Kim, Bilge Soran, Raghuraman Krishnamoorthi, Mohamed Elhoseiny, Vikas Chandra
    conference_short: ICML
    conference: ICML 2025
    pdf: https://arxiv.org/abs/2410.17434
    code: https://github.com/Vision-CAIR/LongVU
    page: https://vision-cair.github.io/LongVU
    image: ./assets/img/pub/longvu.png
    notes: Work done at Meta
    type: mllm

  - title: "StoryGPT-V: Large Language Models as Consistent Story Visualizers"
    authors: <strong><u>Xiaoqian Shen</u></strong>, Mohamed Elhoseiny
    conference_short: CVPR
    conference: CVPR 2025
    pdf: https://arxiv.org/abs/2312.02252
    code: https://github.com/xiaoqian-shen/StoryGPT-V
    video: ./assets/img/pub/storygptv.mp4
    page: https://xiaoqian-shen.github.io/StoryGPT-V
    type: mllm,genai

  - title: "MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models"
    authors: Deyao Zhu*, Jun Chen*, <strong><u>Xiaoqian Shen</u></strong>, Xiang Li, Mohamed Elhoseiny
    conference_short: ICLR
    conference: ICLR 2024
    pdf: https://arxiv.org/abs/2304.10592
    code: https://github.com/Vision-CAIR/MiniGPT-4
    page: https://minigpt-4.github.io
    image: ./assets/img/pub/minigpt4.png
    notes: Github 25k+ Stars, 3k+ Cites
    type: mllm

  # - title: "Goldfish: Vision-Language Understanding of Arbitrarily Long Videos"
  #   authors: Kirolos Ataallah, <strong><u>Xiaoqian Shen</u></strong>, Eslam Abdelrahman, Essam Sleiman, Mingchen Zhuge, Jian Ding, Deyao Zhu, JÃ¼rgen Schmidhuber, Mohamed Elhoseiny
  #   conference_short: ECCV
  #   conference: ECCV 2024
  #   pdf: https://arxiv.org/abs/2407.12679
  #   code: https://github.com/Vision-CAIR/MiniGPT4-video
  #   page: https://vision-cair.github.io/Goldfish_website
  #   image: https://vision-cair.github.io/Goldfish_website/repo_imgs/teaser_fig_final_final.jpg
  #   type: mllm

  # - title: "Affective Visual Dialog: A Large-Scale Benchmark for Emotional Reasoning Based on Visually Grounded Conversations"
  #   authors: Kilichbek Haydarov, <strong><u>Xiaoqian Shen</u></strong>, Avinash Madasu, Mahmoud Salem, Li-Jia Li, Gamaleldin Elsayed, Mohamed Elhoseiny
  #   conference_short: ECCV
  #   conference: ECCV 2024
  #   pdf: https://arxiv.org/abs/2308.16349
  #   code: https://github.com/Vision-CAIR/affectiveVisDial
  #   page: https://affective-visual-dialog.github.io
  #   image: ./assets/img/pub/dial.png

#  - title: "Adversarial text to continous image generation"
#    authors: Kilichbek Haydarov, Aashiq Muhamed, <strong><u>Xiaoqian Shen</u></strong>, Jovana Lazarevic, Ivan Skorokhodov, Chamuditha Jayanga Galappaththige, Mohamed Elhoseiny
#    conference_short: CVPR
#    conference: CVPR 2024
#    pdf: https://openaccess.thecvf.com/content/CVPR2024/papers/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.pdf
#    image: ./assets/img/pub/hypercgan.png
#    page: https://hypercgan-web.s3.amazonaws.com/index.html
#    type: genai

  # - title: "MiniGPT-v2: Large Language Model as a Unified Interface for Vision-Language Multi-task Learning"
  #   authors: Jun Chen, Deyao Zhu, <strong><u>Xiaoqian Shen</u></strong>, Xiang Li, Zechun Liu, Pengchuan Zhang, Raghuraman Krishnamoorthi, Vikas Chandra, Yunyang Xiong, Mohamed Elhoseiny
  #   conference: Arxiv preprint 2023
  #   pdf: https://arxiv.org/abs/2310.09478
  #   code: https://github.com/Vision-CAIR/MiniGPT-4
  #   page: https://minigpt-v2.github.io
  #   image: ./assets/img/pub/minigpt-v2.png
  #   type: mllm
  #   is_preprint: true

#  - title: "HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models"
#    authors: Eslam Bakr, <strong><u>Xiaoqian Shen</u></strong>*, Pengzhan Sun*, Faizan Khan*, Erran Li, Mohamed Elhoseiny
#    conference_short: ICCV
#    conference: ICCV 2023
#    pdf: https://arxiv.org/abs/2304.05390
#    code: https://github.com/eslambakr/HRS_benchmark
#    page: https://eslambakr.github.io/hrsbench.github.io
#    image: ./assets/img/pub/hrs.png
#    type: genai

  - title: "MoStGAN-V: Video Generation with Temporal Motion Styles"
    authors: <strong><u>Xiaoqian Shen</u></strong>, Xiang Li, Mohamed Elhoseiny
    conference_short: CVPR
    conference: CVPR 2023
    pdf: https://arxiv.org/abs/2304.02777
    code: https://github.com/xiaoqian-shen/MoStGAN-V
    image: ./assets/img/pub/mostgan.png
    page: https://xiaoqian-shen.github.io/MoStGAN-V
    type: genai

#  - title: "ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions"
#    authors: Deyao Zhu, Jun Chen, Kilichbek Haydarov, <strong><u>Xiaoqian Shen</u></strong>, Wenxuan Zhang, Mohamed Elhoseiny
#    conference_short: TMLR
#    conference: TMLR
#    pdf: https://arxiv.org/abs/2303.06594
#    code: https://github.com/Vision-CAIR/ChatCaptioner
#    image: ./assets/img/pub/chatcap.gif
#    notes: Github 400+ Stars
#    type: mllm

#  - title: "Exploring hierarchical graph representation for large-scale zero-shot image classification"
#    authors: Kai Yi, <strong><u>Xiaoqian Shen</u></strong>, Yunhao Gou, Mohamed Elhoseiny
#    conference: ECCV 2022
#    pdf: https://arxiv.org/abs/2203.01386
#    image: ./assets/img/pub/hgr-net.png
#    code: https://github.com/WilliamYi96/hgr-net
#    page: https://kaiyi.me/p/hgrnet
#    conference_short: ECCV

#  - title: "Multi-ConDoS: Multimodal Contrastive Domain Sharing Generative Adversarial Networks for Self-Supervised Medical Image Segmentation"
#    authors: Jiaojiao Zhang, Shuo Zhang, <strong><u>Xiaoqian Shen</u></strong>, Thomas Lukasiewicz, Zhenghua Xu
#    conference: IEEE Transactions on Medical Imaging
#    pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10167829
#    image: ./assets/img/pub/condos.png
#    conference_short: TMI
