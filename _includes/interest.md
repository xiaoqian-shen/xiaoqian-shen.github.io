## Research Interests

<style>
  .paper-tag {
    font-size: 0.7em;
    color: #555;
    font-weight: normal;
  }

  .paper-link {
    text-decoration: none;
    color: #069;
    font-weight: normal;
  }
</style>

- **Generative Models:** Image Generation (<a class="paper-link" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.pdf">HyperCGAN<sub class="paper-tag">CVPR</sub></a>), Video Generation (<a class="paper-link" href="https://arxiv.org/abs/2304.02777">MoStGAN-V<sub class="paper-tag">CVPR</sub></a>)
- **Vision-Language:** Multi-Modal Comprehension (<a class="paper-link" href="https://arxiv.org/abs/2410.17434">LongVU<sub class="paper-tag">ICML</sub></a>, <a class="paper-link" href="https://arxiv.org/abs/2407.12679">GoldFish<sub class="paper-tag">ECCV</sub></a>, <a class="paper-link" href="https://arxiv.org/abs/2304.10592">MiniGPT-4<sub class="paper-tag">ICLR</sub></a>) and Generation (<a class="paper-link" href="https://arxiv.org/abs/2312.02252">StoryGPT-V<sub class="paper-tag">CVPR</sub></a>)
